{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiresolution Hash Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from multiresolution_hash_encoding import MultiresolutionHashEncoding\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder(torch.nn.Module):\n",
    "    def __init__(self, image_dims, use_color=False):\n",
    "        super().__init__()\n",
    "        self.encoding = MultiresolutionHashEncoding(2**14, 2, 2, levels=16, N_min=16, N_max=image_dims)\n",
    "        self.mlp = nn.ModuleList(\n",
    "            [nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 3 if use_color else 1),\n",
    "            nn.Sigmoid()]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoding(x)\n",
    "        for layer in self.mlp:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "def PSNR(img:np.ndarray, target:np.ndarray):\n",
    "    mse = np.square(img - target).mean()\n",
    "    psne = 10 * np.log10((1) / mse)\n",
    "    return psne\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_full(m:ImageEncoder, img:Image) -> np.ndarray:\n",
    "    pred_np_im = np.empty((img.height, img.width), dtype=np.float32)\n",
    "    inputs = np.mgrid[0:img.height, 0:img.width].T.reshape(-1, 2)\n",
    "    batch_size = int(np.ceil(inputs.shape[0] / 5))\n",
    "    for i in range(5):\n",
    "        indices = inputs[i * batch_size:(i+1) * batch_size]\n",
    "        pred_im = m(torch.tensor(\n",
    "                    indices, device='cuda:0'\n",
    "                ) / im_dim )\n",
    "        pred_np_im[indices[:,0], indices[:,1]] = pred_im.cpu().numpy().flatten()\n",
    "    return pred_np_im\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"test_files/albert.jpg\")\n",
    "\n",
    "im_dim = max(img.width, img.height)\n",
    "\n",
    "m = ImageEncoder(im_dim).cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "            [{'params': m.encoding.parameters()}, {'params':m.mlp.parameters(), 'weight_decay':1e-6}],\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-15,\n",
    "            lr = 1e-2)\n",
    "\n",
    "loss_func = torch.nn.MSELoss()\n",
    "\n",
    "grid = np.mgrid[0:img.height, 0:img.width].T.reshape(-1, 2)\n",
    "np.random.shuffle(grid)\n",
    "grid:List[np.ndarray] = [grid[i * BATCH_SIZE:(i+1) * BATCH_SIZE] for i in range(int(np.ceil(len(grid) / BATCH_SIZE)))]\n",
    "print(f\"Image batch size ({img.width}, {img.height})\")\n",
    "\n",
    "np_img = np.array(img).astype(np.float32) / 255.0\n",
    "\n",
    "loss_list = []\n",
    "psnr_list = []\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    for j, inp in enumerate(grid):\n",
    "        im = torch.tensor(np_img[inp[:,0], inp[:,1]], device='cuda:0')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_im = m(torch.tensor(inp.astype(np.float32) / im_dim, device='cuda:0'))\n",
    "\n",
    "        loss:torch.Tensor = loss_func(pred_im.reshape(im.shape), im)\n",
    "        \n",
    "        print(f\"Batch: {i + 1}/{EPOCHS}, Step: {j + 1}/{len(grid)}, loss:{loss.detach().cpu()}.\")\n",
    "\n",
    "        loss_list.append(loss.detach().cpu())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    psnr = PSNR(predict_full(m, img), np_img)\n",
    "    psnr_list.append(psnr)\n",
    "    print(f\"PSNR: {psnr}\")\n",
    "\n",
    "loss_list = np.array(loss_list)\n",
    "psnr_list = np.array(psnr_list)\n",
    "\n",
    "plt.plot(loss_list)\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.figure()\n",
    "plt.plot(psnr_list)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"PSNE\")\n",
    "\n",
    "optimizer.zero_grad(True)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "118c1032304a1c3d5ab877c7ca5dd46a137cf26799d1b97c9d6f700ce3d620cd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('torch-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
